{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasan\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 192, 256])\n",
      "torch.Size([1, 192, 256])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from Logger import Logger\n",
    "from utils import *\n",
    "from DataLoader import DataLoader\n",
    "from Discriminator import Discriminator\n",
    "from Generator import Generator\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(r'C:\\Users\\pasan\\Documents\\Notebooks\\Saliency\\logger.txt')\n",
    "batch_size = 20\n",
    "lr = 0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ReLU(inplace) Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ReLU(inplace) MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ReLU(inplace) Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ReLU(inplace) MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ReLU(inplace) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ReLU(inplace) MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ReLU(inplace) Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ReLU(inplace) Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ReLU(inplace) MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ReLU(inplace) Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ReLU(inplace) Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ReLU(inplace)\n"
     ]
    }
   ],
   "source": [
    "discriminator = Discriminator()\n",
    "generator = Generator()\n",
    "if torch.cuda.is_available():\n",
    "    discriminator.cuda()\n",
    "    generator.cuda()\n",
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x0000026915DB0830> <generator object Module.parameters at 0x0000026915DB0A98>\n"
     ]
    }
   ],
   "source": [
    "print(discriminator.parameters(), generator.parameters())\n",
    "d_optim = torch.optim.Adagrad(discriminator.parameters(), lr = lr)\n",
    "g_optim = torch.optim.Adagrad(generator.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 3 #125 for actual training gpu bound\n",
    "dataloader = DataLoader(batch_size)\n",
    "num_batch = dataloader.num_batches\n",
    "num_batch = int(num_batch)\n",
    "print(num_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_variable(x, requires_grad = True):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x, requires_grad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator...\n",
      "before convs1\n",
      "after convs1 torch.Size([20, 3, 192, 256])\n",
      "after convs2 torch.Size([20, 32, 96, 128])\n",
      "after convs3 torch.Size([20, 64, 48, 64])\n",
      "after convs4 torch.Size([20, 64, 48, 64])\n",
      "after convs5 torch.Size([20, 64, 24, 32])\n",
      "x size torch.Size([20, 64, 24, 32])\n",
      "torch.Size([64, 24, 32])\n",
      "torch.Size([20, 49152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_real_loss =  tensor(0.7687)\n",
      "OUTPUTS tensor([0.4637, 0.4636, 0.4637, 0.4637, 0.4637, 0.4636, 0.4637, 0.4635, 0.4636,\n",
      "        0.4637, 0.4636, 0.4636, 0.4637, 0.4637, 0.4636, 0.4636, 0.4636, 0.4635,\n",
      "        0.4636, 0.4636], grad_fn=<SqueezeBackward0>)\n",
      "D_LOSS tensor(-15.3731, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "C:\\Users\\pasan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:79: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], step[1/500], d_loss: -15.3731, D(x): 0.46, time: 6.8078\n",
      "Training Generator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasan\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before convs1\n",
      "after convs1 torch.Size([20, 3, 192, 256])\n",
      "after convs2 torch.Size([20, 32, 96, 128])\n",
      "after convs3 torch.Size([20, 64, 48, 64])\n",
      "after convs4 torch.Size([20, 64, 48, 64])\n",
      "after convs5 torch.Size([20, 64, 24, 32])\n",
      "x size torch.Size([20, 64, 24, 32])\n",
      "torch.Size([64, 24, 32])\n",
      "torch.Size([20, 49152])\n",
      "g_gen_loss tensor(0.6545, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "g_dis_loss tensor([[1.0059],\n",
      "        [1.0102],\n",
      "        [1.0132],\n",
      "        [1.0118],\n",
      "        [1.0112],\n",
      "        [1.0112],\n",
      "        [1.0142],\n",
      "        [1.0127],\n",
      "        [1.0105],\n",
      "        [1.0083],\n",
      "        [1.0147],\n",
      "        [1.0107],\n",
      "        [1.0126],\n",
      "        [1.0133],\n",
      "        [1.0149],\n",
      "        [1.0126],\n",
      "        [1.0059],\n",
      "        [1.0141],\n",
      "        [1.0097],\n",
      "        [1.0124]], grad_fn=<NegBackward>)\n",
      "g_loss tensor(20.8847, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "C:\\Users\\pasan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:82: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], step[2/500], d_loss: -15.3731, g_loss: 20.8847, D(x): 0.46, D(G(x)): 0.36, time: 656.3924\n",
      "Training Discriminator...\n",
      "before convs1\n",
      "after convs1 torch.Size([20, 3, 192, 256])\n",
      "after convs2 torch.Size([20, 32, 96, 128])\n",
      "after convs3 torch.Size([20, 64, 48, 64])\n",
      "after convs4 torch.Size([20, 64, 48, 64])\n",
      "after convs5 torch.Size([20, 64, 24, 32])\n",
      "x size torch.Size([20, 64, 24, 32])\n",
      "torch.Size([64, 24, 32])\n",
      "torch.Size([20, 49152])\n",
      "D_real_loss =  tensor(1.0117)\n",
      "OUTPUTS tensor([0.3641, 0.3635, 0.3632, 0.3642, 0.3641, 0.3636, 0.3642, 0.3638, 0.3634,\n",
      "        0.3639, 0.3639, 0.3636, 0.3628, 0.3639, 0.3639, 0.3632, 0.3639, 0.3628,\n",
      "        0.3627, 0.3633], grad_fn=<SqueezeBackward0>)\n",
      "D_LOSS tensor(-20.2337, grad_fn=<SumBackward0>)\n",
      "Epoch [1/3], step[3/500], d_loss: -20.2337, g_loss: 20.8847, D(x): 0.36, D(G(x)): 0.36, time: 667.5655\n",
      "Epoch: 1  train_loss-> (tensor(-0.0712), tensor(0.0418))\n",
      "NEW PATH C:\\Users\\pasan\\Documents\\Notebooks\\Saliency\\SavedStates\\generator_output/1.png\n",
      "Image saved to  C:\\Users\\pasan\\Documents\\Notebooks\\Saliency\\SavedStates\\generator_output/1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████████▋                                                       | 1/3 [11:15<22:31, 675.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator...\n",
      "before convs1\n",
      "after convs1 torch.Size([20, 3, 192, 256])\n",
      "after convs2 torch.Size([20, 32, 96, 128])\n",
      "after convs3 torch.Size([20, 64, 48, 64])\n",
      "after convs4 torch.Size([20, 64, 48, 64])\n",
      "after convs5 torch.Size([20, 64, 24, 32])\n",
      "x size torch.Size([20, 64, 24, 32])\n",
      "torch.Size([64, 24, 32])\n",
      "torch.Size([20, 49152])\n",
      "D_real_loss =  tensor(1.1728)\n",
      "OUTPUTS tensor([0.3103, 0.3089, 0.3093, 0.3110, 0.3093, 0.3079, 0.3096, 0.3090, 0.3092,\n",
      "        0.3089, 0.3092, 0.3106, 0.3100, 0.3086, 0.3091, 0.3098, 0.3105, 0.3095,\n",
      "        0.3091, 0.3100], grad_fn=<SqueezeBackward0>)\n",
      "D_LOSS tensor(-23.4568, grad_fn=<SumBackward0>)\n",
      "Epoch [2/3], step[1/500], d_loss: -23.4568, D(x): 0.31, time: 683.7638\n",
      "Training Generator...\n",
      "before convs1\n",
      "after convs1 torch.Size([20, 3, 192, 256])\n",
      "after convs2 torch.Size([20, 32, 96, 128])\n",
      "after convs3 torch.Size([20, 64, 48, 64])\n",
      "after convs4 torch.Size([20, 64, 48, 64])\n",
      "after convs5 torch.Size([20, 64, 24, 32])\n",
      "x size torch.Size([20, 64, 24, 32])\n",
      "torch.Size([64, 24, 32])\n",
      "torch.Size([20, 49152])\n",
      "g_gen_loss tensor(0.6313, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "g_dis_loss tensor([[1.2409],\n",
      "        [1.2449],\n",
      "        [1.2449],\n",
      "        [1.2426],\n",
      "        [1.2459],\n",
      "        [1.2447],\n",
      "        [1.2447],\n",
      "        [1.2473],\n",
      "        [1.2458],\n",
      "        [1.2475],\n",
      "        [1.2453],\n",
      "        [1.2404],\n",
      "        [1.2404],\n",
      "        [1.2417],\n",
      "        [1.2443],\n",
      "        [1.2425],\n",
      "        [1.2459],\n",
      "        [1.2417],\n",
      "        [1.2409],\n",
      "        [1.2497]], grad_fn=<NegBackward>)\n",
      "g_loss tensor(25.5133, grad_fn=<SumBackward0>)\n",
      "Epoch [2/3], step[2/500], d_loss: -23.4568, g_loss: 25.5133, D(x): 0.31, D(G(x)): 0.29, time: 1214.1046\n",
      "Training Discriminator...\n",
      "before convs1\n",
      "after convs1 torch.Size([20, 3, 192, 256])\n",
      "after convs2 torch.Size([20, 32, 96, 128])\n",
      "after convs3 torch.Size([20, 64, 48, 64])\n",
      "after convs4 torch.Size([20, 64, 48, 64])\n",
      "after convs5 torch.Size([20, 64, 24, 32])\n",
      "x size torch.Size([20, 64, 24, 32])\n",
      "torch.Size([64, 24, 32])\n",
      "torch.Size([20, 49152])\n",
      "D_real_loss =  tensor(1.2466)\n",
      "OUTPUTS tensor([0.2862, 0.2876, 0.2878, 0.2873, 0.2861, 0.2866, 0.2866, 0.2871, 0.2878,\n",
      "        0.2879, 0.2873, 0.2876, 0.2880, 0.2874, 0.2883, 0.2872, 0.2886, 0.2874,\n",
      "        0.2878, 0.2892], grad_fn=<SqueezeBackward0>)\n",
      "D_LOSS tensor(-24.9314, grad_fn=<SumBackward0>)\n",
      "Epoch [2/3], step[3/500], d_loss: -24.9314, g_loss: 25.5133, D(x): 0.29, D(G(x)): 0.29, time: 1226.6745\n",
      "Epoch: 2  train_loss-> (tensor(-0.0968), tensor(0.0510))\n",
      "NEW PATH C:\\Users\\pasan\\Documents\\Notebooks\\Saliency\\SavedStates\\generator_output/2.png\n",
      "Image saved to  C:\\Users\\pasan\\Documents\\Notebooks\\Saliency\\SavedStates\\generator_output/2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [20:31<10:39, 639.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator...\n",
      "before convs1\n",
      "after convs1 torch.Size([20, 3, 192, 256])\n",
      "after convs2 torch.Size([20, 32, 96, 128])\n",
      "after convs3 torch.Size([20, 64, 48, 64])\n",
      "after convs4 torch.Size([20, 64, 48, 64])\n",
      "after convs5 torch.Size([20, 64, 24, 32])\n",
      "x size torch.Size([20, 64, 24, 32])\n",
      "torch.Size([64, 24, 32])\n",
      "torch.Size([20, 49152])\n",
      "D_real_loss =  tensor(1.2741)\n",
      "OUTPUTS tensor([0.2790, 0.2791, 0.2808, 0.2794, 0.2801, 0.2798, 0.2802, 0.2789, 0.2784,\n",
      "        0.2791, 0.2801, 0.2803, 0.2796, 0.2795, 0.2796, 0.2795, 0.2801, 0.2803,\n",
      "        0.2800, 0.2796], grad_fn=<SqueezeBackward0>)\n",
      "D_LOSS tensor(-25.4829, grad_fn=<SumBackward0>)\n",
      "Epoch [3/3], step[1/500], d_loss: -25.4829, D(x): 0.28, time: 1239.4224\n",
      "Training Generator...\n",
      "before convs1\n",
      "after convs1 torch.Size([20, 3, 192, 256])\n",
      "after convs2 torch.Size([20, 32, 96, 128])\n",
      "after convs3 torch.Size([20, 64, 48, 64])\n",
      "after convs4 torch.Size([20, 64, 48, 64])\n",
      "after convs5 torch.Size([20, 64, 24, 32])\n",
      "x size torch.Size([20, 64, 24, 32])\n",
      "torch.Size([64, 24, 32])\n",
      "torch.Size([20, 49152])\n",
      "g_gen_loss tensor(0.6322, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "g_dis_loss tensor([[1.2805],\n",
      "        [1.2870],\n",
      "        [1.2868],\n",
      "        [1.2850],\n",
      "        [1.2860],\n",
      "        [1.2855],\n",
      "        [1.2881],\n",
      "        [1.2887],\n",
      "        [1.2893],\n",
      "        [1.2801],\n",
      "        [1.2887],\n",
      "        [1.2884],\n",
      "        [1.2849],\n",
      "        [1.2838],\n",
      "        [1.2858],\n",
      "        [1.2875],\n",
      "        [1.2874],\n",
      "        [1.2851],\n",
      "        [1.2850],\n",
      "        [1.2855]], grad_fn=<NegBackward>)\n",
      "g_loss tensor(26.3515, grad_fn=<SumBackward0>)\n",
      "Epoch [3/3], step[2/500], d_loss: -25.4829, g_loss: 26.3515, D(x): 0.28, D(G(x)): 0.28, time: 1864.9017\n",
      "Training Discriminator...\n",
      "before convs1\n",
      "after convs1 torch.Size([20, 3, 192, 256])\n",
      "after convs2 torch.Size([20, 32, 96, 128])\n",
      "after convs3 torch.Size([20, 64, 48, 64])\n",
      "after convs4 torch.Size([20, 64, 48, 64])\n",
      "after convs5 torch.Size([20, 64, 24, 32])\n",
      "x size torch.Size([20, 64, 24, 32])\n",
      "torch.Size([64, 24, 32])\n",
      "torch.Size([20, 49152])\n",
      "D_real_loss =  tensor(1.2857)\n",
      "OUTPUTS tensor([0.2760, 0.2760, 0.2759, 0.2763, 0.2772, 0.2761, 0.2765, 0.2758, 0.2779,\n",
      "        0.2757, 0.2762, 0.2762, 0.2752, 0.2760, 0.2788, 0.2766, 0.2779, 0.2758,\n",
      "        0.2758, 0.2774], grad_fn=<SqueezeBackward0>)\n",
      "D_LOSS tensor(-25.7136, grad_fn=<SumBackward0>)\n",
      "Epoch [3/3], step[3/500], d_loss: -25.7136, g_loss: 26.3515, D(x): 0.28, D(G(x)): 0.28, time: 1876.6436\n",
      "Epoch: 3  train_loss-> (tensor(-0.1024), tensor(0.0527))\n",
      "NEW PATH C:\\Users\\pasan\\Documents\\Notebooks\\Saliency\\SavedStates\\generator_output/3.png\n",
      "Image saved to  C:\\Users\\pasan\\Documents\\Notebooks\\Saliency\\SavedStates\\generator_output/3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [31:19<00:00, 642.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "g_loss = 0\n",
    "fake_score = 0\n",
    "start_time = time.time()\n",
    "DIR_TO_SAVE = r\"C:\\Users\\pasan\\Documents\\Notebooks\\Saliency\\SavedStates\\generator_output\"\n",
    "if not os.path.exists(DIR_TO_SAVE):\n",
    "    os.makedirs(DIR_TO_SAVE)\n",
    "validation_sample = cv2.imread(r\"C:\\Users\\pasan\\Documents\\Notebooks\\Saliency\\ResizedImages\\images256x192_val\\COCO_val2014_000000143859.png\")\n",
    "validation_sample = cv2.cvtColor(validation_sample, cv2.COLOR_BGR2RGB)\n",
    "validation_sample = Image.fromarray(validation_sample)\n",
    "\n",
    "for current_epoch in tqdm (range(1, num_epoch+1)):\n",
    "    n_updates = 1\n",
    "    d_cost_avg = 0\n",
    "    g_cost_avg = 0\n",
    "    \n",
    "    for i in range(3):\n",
    "        \n",
    "        (batch_img, batch_map) = dataloader.get_batch()\n",
    "        batch_img = to_variable(batch_img, requires_grad=True)\n",
    "        batch_map = to_variable(batch_map, requires_grad=False)\n",
    "        real_labels = to_variable(torch.FloatTensor(np.ones(batch_size, dtype = float)), requires_grad = False)\n",
    "        fake_labels = to_variable(torch.FloatTensor(np.zeros(batch_size, dtype = float)), requires_grad = False)\n",
    "        \n",
    "        if n_updates % 2 == 1:\n",
    "            \n",
    "            print(\"Training Discriminator...\")\n",
    "            d_optim.zero_grad()\n",
    "            inp_d = torch.cat((batch_img, batch_map), 1)\n",
    "            if i == 1 :\n",
    "                print('INP_D', inp_d)\n",
    "            outputs = discriminator(inp_d).squeeze()\n",
    "            d_real_loss = loss_function(outputs, real_labels)\n",
    "            print('D_real_loss = ', d_real_loss.data[0])\n",
    "            print('OUTPUTS', outputs)\n",
    "            real_score = outputs.data.mean()\n",
    "            \n",
    "            d_loss = torch.sum(torch.log(outputs))\n",
    "            print('D_LOSS', d_loss)\n",
    "            d_cost_avg += d_loss.data[0]\n",
    "            \n",
    "            d_loss.backward()\n",
    "            d_loss.register_hook(print)\n",
    "            d_optim.step()\n",
    "            \n",
    "#             info = {'d_loss' : d_loss.data[0],\n",
    "#                  'real_score_mean' : real_score,}\n",
    "           \n",
    "#             for tag, value in info.items():\n",
    "#                 logger.scalar_summary(tag, value, counter)\n",
    "        else :\n",
    "            print('Training Generator...')\n",
    "            g_optim.zero_grad()\n",
    "            fake_map = generator(batch_img)\n",
    "            inp_d = torch.cat((batch_img,fake_map),1)\n",
    "            outputs = discriminator(inp_d)\n",
    "            fake_score = outputs.data.mean()\n",
    "            \n",
    "            g_gen_loss = loss_function(fake_map, batch_map)\n",
    "            print('g_gen_loss', g_gen_loss)\n",
    "            g_dis_loss = -torch.log(outputs)\n",
    "            print ('g_dis_loss', g_dis_loss)\n",
    "            alpha = 0.05\n",
    "            g_loss = torch.sum(g_dis_loss + alpha * g_gen_loss)\n",
    "            print('g_loss', g_loss)\n",
    "            g_cost_avg += g_loss.data[0]\n",
    "            g_loss.backward()\n",
    "            g_optim.step()\n",
    "#             info = {\n",
    "#                   'g_loss' : g_loss.data[0],\n",
    "#                   'fake_score_mean' : fake_score,\n",
    "#             }\n",
    "#             for tag,value in info.items():\n",
    "#                 logger.scalar_summary(tag, value, counter,i)\n",
    "        \n",
    "        \n",
    "        if n_updates == 1:\n",
    "            print(\"Epoch [%d/%d], step[%d/%d], d_loss: %.4f, D(x): %.2f, time: %4.4f\"\n",
    "                  %(current_epoch, num_epoch, i+1, num_batch, d_loss.data[0],  real_score, time.time()-start_time) )\n",
    "        else:\n",
    "            print(\"Epoch [%d/%d], step[%d/%d], d_loss: %.4f, g_loss: %.4f, D(x): %.2f, D(G(x)): %.2f, time: %4.4f\"\n",
    "                  %(current_epoch, num_epoch, i+1, num_batch, d_loss.data[0], g_loss.data[0],\n",
    "                    real_score, fake_score, time.time()-start_time) )\n",
    "        counter += 1\n",
    "        n_updates += 1\n",
    "    d_cost_avg /= num_batch\n",
    "    g_cost_avg /= num_batch\n",
    "    print('Epoch:', current_epoch, ' train_loss->', (d_cost_avg, g_cost_avg))\n",
    "    torch.save(generator.state_dict(), r'C:\\Users\\pasan\\Documents\\Notebooks\\Saliency\\SavedStates/generator.pkl')\n",
    "    torch.save(discriminator.state_dict(), r'C:\\Users\\pasan\\Documents\\Notebooks\\Saliency\\SavedStates/discriminator.pkl')\n",
    "    predict(generator, validation_sample, current_epoch, DIR_TO_SAVE)\n",
    "torch.save(generator.state_dict(),r'C:\\Users\\pasan\\Documents\\Notebooks\\Saliency\\SavedStates/generator.pkl')\n",
    "torch.save(discriminator.state_dict(), r'C:\\Users\\pasan\\Documents\\Notebooks\\Saliency\\SavedStates/discriminator.pkl')\n",
    "print('Done')\n",
    "\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
